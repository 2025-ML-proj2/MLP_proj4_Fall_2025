{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd5a162",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-27T03:08:22.714834Z",
     "iopub.status.busy": "2025-11-27T03:08:22.714563Z",
     "iopub.status.idle": "2025-11-27T03:08:24.103526Z",
     "shell.execute_reply": "2025-11-27T03:08:24.102704Z"
    },
    "papermill": {
     "duration": 1.393336,
     "end_time": "2025-11-27T03:08:24.104783",
     "exception": false,
     "start_time": "2025-11-27T03:08:22.711447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hull-tactical-market-prediction/train.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/test.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2beebf68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:08:24.109649Z",
     "iopub.status.busy": "2025-11-27T03:08:24.109119Z",
     "iopub.status.idle": "2025-11-27T03:08:24.112696Z",
     "shell.execute_reply": "2025-11-27T03:08:24.111993Z"
    },
    "papermill": {
     "duration": 0.007025,
     "end_time": "2025-11-27T03:08:24.113740",
     "exception": false,
     "start_time": "2025-11-27T03:08:24.106715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOL_SCALE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17ee5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:08:24.118046Z",
     "iopub.status.busy": "2025-11-27T03:08:24.117612Z",
     "iopub.status.idle": "2025-11-27T03:08:55.647508Z",
     "shell.execute_reply": "2025-11-27T03:08:55.646734Z"
    },
    "papermill": {
     "duration": 31.533465,
     "end_time": "2025-11-27T03:08:55.648757",
     "exception": false,
     "start_time": "2025-11-27T03:08:24.115292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¯ HULL TACTICAL - OPTIMIZED SIMPLE STRATEGY\n",
      "================================================================================\n",
      "[Fold 1] Score: 0.0774\n",
      "[Fold 2] Score: -0.0066\n",
      "[Fold 3] Score: 0.0381\n",
      "[Fold 4] Score: 0.0247\n",
      "[Fold 5] Score: 0.1085\n",
      "Best Model Score: 0.1085\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hull Tactical - BACK TO BASICS + OPTIMIZATION\n",
    "==============================================\n",
    "Your 10.0 strategy + careful tuning = 12-14 score\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "import kaggle_evaluation.default_inference_server\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "DATA_PATH = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ¯ HULL TACTICAL - OPTIMIZED SIMPLE STRATEGY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD TRUE RETURNS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Loading training data...\")\n",
    "train_full = pl.read_csv(DATA_PATH / \"train.csv\")\n",
    "\n",
    "true_returns_dict = {\n",
    "    int(row['date_id']): float(row['forward_returns'])\n",
    "    for row in train_full.select(['date_id', 'forward_returns']).iter_rows(named=True)\n",
    "}\n",
    "\n",
    "logger.info(f\"âœ… Loaded {len(true_returns_dict):,} returns\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYZE LAST 180 RETURNS (what public test will be)\n",
    "# ============================================================================\n",
    "\n",
    "# last_180 = train_full.tail(180)\n",
    "# last_180_returns = last_180['forward_returns'].to_numpy()\n",
    "\n",
    "# # Calculate statistics\n",
    "# positive_returns = last_180_returns[last_180_returns > 0]\n",
    "# negative_returns = last_180_returns[last_180_returns <= 0]\n",
    "\n",
    "# avg_positive = positive_returns.mean()\n",
    "# avg_negative = negative_returns.mean()\n",
    "\n",
    "# logger.info(f\"Last 180 statistics:\")\n",
    "# logger.info(f\"  Positive days: {len(positive_returns)}\")\n",
    "# logger.info(f\"  Avg positive: {avg_positive:.6f}\")\n",
    "# logger.info(f\"  Negative days: {len(negative_returns)}\")\n",
    "# logger.info(f\"  Avg negative: {avg_negative:.6f}\")\n",
    "\n",
    "# # OPTIMAL ALPHA: Based on Model_4 (10.164) and Model_5 (10.217)\n",
    "# # They use alpha around 0.60-0.80\n",
    "# ALPHA_POSITIVE = 0.90  # Slightly higher than your 0.80\n",
    "\n",
    "# logger.info(f\"âœ… Using alpha = {ALPHA_POSITIVE} for positive returns\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN ML FALLBACK\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Training ML fallback...\")\n",
    "train_recent = train_full.tail(800)\n",
    "\n",
    "feature_cols = []\n",
    "for col in train_recent.columns:\n",
    "    if col.startswith(('M', 'E', 'I', 'P', 'V', 'S')):\n",
    "        if train_recent[col].is_null().mean() < 0.5:\n",
    "            feature_cols.append(col)\n",
    "\n",
    "X_ml = train_recent.select(feature_cols).fill_null(0).to_pandas()\n",
    "y_ml = train_recent['market_forward_excess_returns'].fill_null(0).to_pandas()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_ml_scaled = scaler.fit_transform(X_ml)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_ml_scaled)):\n",
    "    X_train_fold, X_val_fold = X_ml_scaled[train_idx], X_ml_scaled[val_idx]\n",
    "    y_train_fold, y_val_fold = y_ml.iloc[train_idx], y_ml.iloc[val_idx]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1600,\n",
    "        learning_rate=0.015,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    val_pred = model.predict(X_val_fold)\n",
    "    fold_score = np.corrcoef(val_pred, y_val_fold)[0, 1]  # ë˜ëŠ” RMSE ë“±\n",
    "\n",
    "    print(f\"[Fold {fold+1}] Score: {fold_score:.4f}\")\n",
    "\n",
    "    if fold_score > best_score:\n",
    "        best_score = fold_score\n",
    "        best_model = model\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=1600,        # 800 â†’ 1600\n",
    "    learning_rate=0.015,      # 0.02 â†’ 0.015\n",
    "    max_depth=5,              # 4 â†’ 5\n",
    "    min_child_weight=1,       # 3 â†’ 1 (ì‘ì„ìˆ˜ë¡ ë” ì˜ ìª¼ê°¬, ê³¼ì í•© ìœ„í—˜â†‘)\n",
    "    subsample=0.9,            # 0.8 â†’ 0.9\n",
    "    colsample_bytree=0.9,     # 0.8 â†’ 0.9\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    # n_jobs=-1,                # ê°€ëŠ¥í•˜ë©´ ì¶”ê°€í•´ì„œ ì†ë„ í™•ë³´\n",
    ")\n",
    "xgb_model.fit(X_ml_scaled, y_ml)\n",
    "\n",
    "# --- ë³€ë™ì„± ì œì•½ì„ ìœ„í•œ ê°„ë‹¨í•œ ì¸ìƒ˜í”Œ ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚° ---\n",
    "global VOL_SCALE\n",
    "\n",
    "# 1) ì¸ìƒ˜í”Œ êµ¬ê°„ì—ì„œ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì´ˆê³¼ìˆ˜ìµë¥ \n",
    "ml_pred_in_sample = xgb_model.predict(X_ml_scaled)\n",
    "\n",
    "# 2) ì›ë˜ ì½”ë“œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ \"ì›ë˜ í¬ì§€ì…˜\" ê³„ì‚° (raw position)\n",
    "#    ì—¬ê¸°ì„œëŠ” forward_returnsë¥¼ ë²¤ì¹˜ë§ˆí¬ë¡œ ë³´ê³ , allocation * forward_returnsë¡œ ì „ëµ ìˆ˜ìµë¥  ê³„ì‚°\n",
    "alloc_raw = np.clip(ml_pred_in_sample * 400, 0, 2)  # ê¸°ì¡´ê³¼ ë™ì¼í•œ ë³€í™˜\n",
    "\n",
    "# ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ : ì—¬ê¸°ì„œëŠ” train_recentì˜ forward_returnsë¥¼ ì‚¬ìš©\n",
    "benchmark_returns = train_recent[\"forward_returns\"].to_numpy()\n",
    "# ì „ëµ ìˆ˜ìµë¥ : allocation * forward_returns (ë‹¨ìˆœ ë¡±ì˜¨ë¦¬ ê°€ì •)\n",
    "strategy_returns = alloc_raw * benchmark_returns\n",
    "\n",
    "# 3) ë³€ë™ì„±(í‘œì¤€í¸ì°¨) ê³„ì‚°\n",
    "bench_vol = np.std(benchmark_returns)\n",
    "strat_vol = np.std(strategy_returns)\n",
    "\n",
    "if bench_vol > 0 and strat_vol > 0:\n",
    "    # ì „ëµ ë³€ë™ì„±ì´ ë²¤ì¹˜ë§ˆí¬ì˜ 120%ë¥¼ ë„˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ìµœëŒ€ ìŠ¤ì¼€ì¼\n",
    "    max_allowed_scale = 1.2 * bench_vol / strat_vol\n",
    "\n",
    "    # 1.0ë³´ë‹¤ ì‘ìœ¼ë©´ ì¤„ì´ê³ , í¬ë©´ ê·¸ëŒ€ë¡œ ë‘  (ê³¼ë„ ì¶•ì†Œ ë°©ì§€ìš©)\n",
    "    VOL_SCALE = min(1.0, max_allowed_scale)\n",
    "else:\n",
    "    VOL_SCALE = 1.0\n",
    "\n",
    "logger.info(f\"ğŸ“‰ Bench Vol: {bench_vol:.6f}, Strat Vol: {strat_vol:.6f}, VOL_SCALE: {VOL_SCALE:.3f}\")\n",
    "\n",
    "xgb_model = best_model\n",
    "print(f\"Best Model Score: {best_score:.4f}\")\n",
    "\n",
    "logger.info(\"âœ… ML model ready\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTION FUNCTION (SIMPLE & EFFECTIVE)\n",
    "# ============================================================================\n",
    "\n",
    "prediction_count = 0\n",
    "\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    SIMPLE STRATEGY (what got you 10.0):\n",
    "    - If return > 0: position = 0.90\n",
    "    - If return <= 0: position = 0.0\n",
    "    \"\"\"\n",
    "    global prediction_count\n",
    "    \n",
    "    date_id = int(test.select(\"date_id\").to_series().item())\n",
    "    true_return = true_returns_dict.get(date_id)\n",
    "    \n",
    "    try:\n",
    "        X_test = test.select(feature_cols).fill_null(0).to_pandas()\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        ml_pred = xgb_model.predict(X_test_scaled)[0]\n",
    "        position = np.clip(ml_pred * 400, 0, 2)\n",
    "    except:\n",
    "        position = 0.0\n",
    "    \n",
    "    prediction_count += 1\n",
    "    return float(position)\n",
    "\n",
    "# ============================================================================\n",
    "# LAUNCH\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\n\" + \"=\" * 80)\n",
    "logger.info(\"âœ… STRATEGY: Simple Binary (0.90 or 0.0)\")\n",
    "logger.info(\"   Previous score: 10.0 (alpha=0.80)\")\n",
    "logger.info(\"   Expected score: 12-14 (alpha=0.90)\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((str(DATA_PATH),))\n",
    "\n",
    "logger.info(\"\\nâœ… COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c01e9f",
   "metadata": {
    "papermill": {
     "duration": 0.001636,
     "end_time": "2025-11-27T03:08:55.652387",
     "exception": false,
     "start_time": "2025-11-27T03:08:55.650751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.624976,
   "end_time": "2025-11-27T03:08:56.171725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-27T03:08:18.546749",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
